{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlsgptj/CJONs/blob/chatbot/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "ZSlnmUdUU_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "eH6E9sjEVFMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxD0KcEiU1t6"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import sentencepiece\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 챗봇에 사용할 BERT 모델과 tokenizer를 로드합니다.\n",
        "chatbot_model_name = \"bert-base-multilingual-cased\"  # 다국어 BERT 모델\n",
        "chatbot_tokenizer = AutoTokenizer.from_pretrained(chatbot_model_name)\n",
        "chatbot_model = AutoModelForSequenceClassification.from_pretrained(chatbot_model_name)"
      ],
      "metadata": {
        "id": "KCgCL6TOU7Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Replace 'your_model_name' with the name of the model you want to use\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Now you should be able to use the tokenizer without errors\n"
      ],
      "metadata": {
        "id": "pQZCRb4CVHvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip list | grep sentencepiece"
      ],
      "metadata": {
        "id": "a9MxlkxrVKj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(input_text):\n",
        "    inputs = chatbot_tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = chatbot_model(**inputs)\n",
        "    response = chatbot_tokenizer.decode(outputs.logits.argmax(dim=-1)[0])\n",
        "    return response"
      ],
      "metadata": {
        "id": "c6aQvUA-VNMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# 데이터 로딩\n",
        "data = [(\"What is wine?\", \"Wine is an alcoholic beverage made from fermented grapes or other fruits.\", 0),\n",
        "(\"What are the different types of wine?\", \"There are several types of wine, including red, white, rosé, sparkling, and dessert wines.\", 1),\n",
        "(\"How is wine made?\", \"Wine is made through the fermentation of grape juice, where yeast converts sugar into alcohol.\", 2),\n",
        "(\"What is the difference between red and white wine?\", \"Red wine is made from red or black grapes and is fermented with the grape skins, while white wine is made from green or yellow grapes and is fermented without the skins.\", 3),\n",
        "(\"How should I store wine at home?\", \"Wine should be stored in a cool, dark place, preferably on its side to keep the cork moist.\", 4),\n",
        "(\"What are tannins in wine?\", \"Tannins are natural compounds found in grape skins, seeds, and stems, which give wine its astringency and bitterness.\", 5),\n",
        "(\"What is the ideal serving temperature for red wine?\", \"Red wine is typically served at room temperature, around 60-65°F (15-18°C).\", 6),\n",
        "(\"How long can I keep an opened bottle of wine?\", \"Once opened, wine can be kept for a few days to a week, depending on the type. Red wines generally last longer than white wines.\", 7),\n",
        "(\"What is the best wine to pair with steak?\", \"A bold red wine, such as Cabernet Sauvignon or Malbec, pairs well with steak.\", 8),\n",
        "(\"What is the difference between dry and sweet wine?\", \"Dry wine has very little residual sugar, while sweet wine has higher sugar content.\", 9),\n",
        "(\"What is the difference between Cabernet Sauvignon and Merlot?\", \"Cabernet Sauvignon is a full-bodied red wine with bold tannins, while Merlot is softer and more approachable with a medium body.\", 10),\n",
        "(\"What is the best wine to pair with cheese?\", \"Red wines like Cabernet Sauvignon, Merlot, or Syrah/Shiraz pair well with hard cheeses, while white wines like Chardonnay or Sauvignon Blanc go well with soft cheeses.\", 11),\n",
        "(\"Can I age sparkling wine?\", \"Most sparkling wines are meant to be consumed young and fresh, and aging may not improve their taste.\", 12),\n",
        "(\"What is the difference between a wine's aroma and its nose?\", \"The aroma refers to the overall smell of the wine, while the nose specifically refers to the smell of the wine in the glass.\", 13),\n",
        "(\"Can I use wine as a marinade?\", \"Yes, wine can be used as a marinade to add flavor and tenderize meat.\", 14),\n",
        "(\"What is the best wine to pair with roast chicken?\", \"Chardonnay or Pinot Noir pair well with roast chicken.\", 15),\n",
        "(\"How do I clean wine glasses?\", \"To clean wine glasses, hand wash them with warm water and mild detergent, and let them air dry to avoid leaving streaks or residue.\", 16),\n",
        "(\"What is the best wine to pair with sushi?\", \"A dry Riesling or a sparkling wine like Champagne go well with sushi.\", 17),\n",
        "(\"What is the difference between a wine's aroma and its taste?\", \"The aroma refers to the smell of the wine, while the taste includes the flavor and mouthfeel experienced on the palate.\", 18),\n",
        "(\"Can I age white wine?\", \"Some high-quality white wines can be aged, but most white wines are meant to be consumed within a few years of purchase.\", 19),\n",
        "(\"Please describe the taste of wine.\", \"Wine has rich fruit flavors and smooth tannins.\", 20),\n",
        "(\"How does wine's acidity feel?\", \"Wine's acidity is tart and refreshing.\", 20),\n",
        "(\"What is tannin?\", \"Tannin is a component in wine that gives it a bitter taste, often found in grape skins or seeds.\", 20),\n",
        "(\"How is the sweetness of wine determined?\", \"The sweetness of wine is determined by the amount of residual sugar it contains.\", 20),\n",
        "(\"Which wine pairs well with meat?\", \"Red wine pairs well with meat.\", 20),\n",
        "(\"What does 'body' mean in wine?\", \"The body of wine refers to its weight or texture, ranging from light-bodied to full-bodied.\", 20),\n",
        "(\"Why does wine taste bitter?\", \"Wine can taste bitter due to the presence of tannins.\", 20),\n",
        "(\"Does higher alcohol content in wine affect its taste?\", \"Higher alcohol content in wine can make it warmer and more intense in flavor.\", 20),\n",
        "(\"Does wine taste better with age?\", \"Some wines can improve with age, gaining more complexity and subtle flavors.\", 20),\n",
        "(\"Is it okay to drink wine warm?\", \"Wine is generally best served slightly chilled.\", 20),\n",
        "(\"Which is better, white wine or red wine?\", \"It depends on individual preferences, but red wines are usually bolder and more complex.\", 20),\n",
        "(\"How do you decant wine?\", \"Decanting involves transferring wine to a separate container, like a decanter or a glass pitcher.\", 20),\n",
        "(\"Why is decanting wine beneficial?\", \"Decanting can soften the wine's acidity and tannins, enhancing its flavors.\", 20),\n",
        "(\"Does the order of wine tasting matter?\", \"The order of wine tasting is important to fully appreciate its characteristics.\", 20),\n",
        "(\"At what temperature should wine be served?\", \"White wine should be served slightly chilled, while red wine can be served at slightly warmer temperatures.\", 20),\n",
        "(\"How should you taste wine to fully experience its flavor?\", \"Before sipping, try to smell the wine and then take a small sip to savor the taste.\", 20),\n",
        "(\"Can you suggest wine and food pairings?\", \"Wines with strong fruit flavors go well with seafood, while red wine pairs nicely with steak.\", 20),\n",
        "(\"How long can you store wine?\", \"The storage time varies depending on the type of wine, but generally, 2-10 years of aging is common.\", 20),\n",
        "(\"Why is aging wine in oak barrels preferred?\", \"Aging wine in oak barrels adds flavors like vanilla and enhances its smoothness.\", 20),\n",
        "(\"How is sweetness created in wine?\", \"Sweetness in wine is created when there is residual sugar in the wine after fermentat\", 20)]  # 라벨링한 데이터를 리스트 형태로 저장\n",
        "\n",
        "# BERT 토크나이저\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 입력 문장과 라벨을 토치 데이터셋으로 변환\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.data[idx][0]\n",
        "        label = self.data[idx][2]\n",
        "\n",
        "        inputs = tokenizer(input_text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "        label = torch.tensor(int(label))\n",
        "\n",
        "        return inputs, label\n",
        "\n",
        "# 데이터셋 준비\n",
        "wine_dataset = WineDataset(data)\n",
        "train_loader = DataLoader(wine_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "NUM_LABELS = 21\n",
        "NUM_EPOCHS = 21\n",
        "\n",
        "# BERT 모델 불러오기\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUM_LABELS)\n",
        "\n",
        "# Optimizer 설정 및 학습\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "labels = labels.to(device)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    inputs, labels = zip(*batch)  # tuple을 풀어줍니다.\n",
        "    inputs = {k: torch.cat([item[k] for item in inputs], dim=0) for k in inputs[0]}  # batch 단위로 concatenate\n",
        "    labels = torch.stack(labels, dim=0)  # batch 단위로 stack\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "train_loader = DataLoader(wine_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "# 학습된 모델을 이용하여 챗봇 구현\n",
        "conversation=[]\n",
        "def wine_chatbot(question):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(question, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_label = torch.argmax(logits).item()\n",
        "\n",
        "    if predicted_label < 0 or predicted_label >= NUM_LABELS:\n",
        "        return \"I apologize, but I couldn't find an answer to that question.\"\n",
        "\n",
        "    # 대화 기록 저장\n",
        "    conversation.append((question, data[predicted_label][1]))\n",
        "\n",
        "    return data[predicted_label][1]\n",
        "\n",
        "# 대화 기록을 출력하는 함수\n",
        "def print_conversation():\n",
        "    print(\"대화 기록:\")\n",
        "    for i, (user_input, bot_response) in enumerate(conversation):\n",
        "        print(f\"{i + 1}. 사용자: {user_input}\")\n",
        "        print(f\"   챗봇: {bot_response}\")\n",
        "        print()\n",
        "\n",
        "# 챗봇 테스트\n",
        "question = \"What is the difference between red and white wine?\"\n",
        "predicted_label = wine_chatbot(question)\n",
        "print(\"Predicted label:\", predicted_label)"
      ],
      "metadata": {
        "id": "Lxmufz-lVXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'wine_chatbot_model.pt')"
      ],
      "metadata": {
        "id": "G6qO9U6mVYNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# 와인 BERT 모델 로드\n",
        "wine_bert_model_name = \"path_to_pretrained_wine_bert\"  # 와인 BERT 모델의 경로나 이름\n",
        "wine_tokenizer = BertTokenizer.from_pretrained(wine_bert_model_name)\n",
        "wine_model = BertModel.from_pretrained(wine_bert_model_name)\n",
        "\n",
        "# 챗봇 BERT 모델 로드\n",
        "chatbot_bert_model_name = \"path_to_pretrained_chatbot_bert\"  # 챗봇 BERT 모델의 경로나 이름\n",
        "chatbot_tokenizer = BertTokenizer.from_pretrained(chatbot_bert_model_name)\n",
        "chatbot_model = BertModel.from_pretrained(chatbot_bert_model_name)\n",
        "\n",
        "# 챗봇 BERT에 와인 BERT 삽입\n",
        "# 예를 들어, 챗봇 BERT의 첫 번째 레이어에 와인 BERT를 삽입하겠습니다.\n",
        "chatbot_model.bert.embeddings.word_embeddings.weight = wine_model.bert.embeddings.word_embeddings.weight\n",
        "\n",
        "# 이제 챗봇 BERT를 사용하여 대화를 수행할 수 있습니다.\n",
        "input_text = \"와인 추천해줘\"\n",
        "inputs = chatbot_tokenizer(input_text, return_tensors=\"pt\")\n",
        "outputs = chatbot_model(**inputs)\n",
        "# 결과로 나온 outputs를 해석하여 적절한 답변을 생성할 수 있습니다.\n",
        "\n",
        "# 이후 모델을 훈련하고 세부적인 파라미터 조정 등을 진행해야 합니다."
      ],
      "metadata": {
        "id": "XZQzUnkqVcJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "F-avwkYj3Vie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#내가 해야 할 일\n",
        "#1. 받은 와인 테스트 데이터를 통해\n",
        "#2. test.csv를 통해 챗봇 구현하기"
      ],
      "metadata": {
        "id": "RQzXq_b9VivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 와인 맛 BERT 모델 로드 함수\n",
        "def load_wine_model(model_path):\n",
        "    config = BertConfig.from_json_file(f\"{model_path}.json\")\n",
        "    model = tf.keras.models.load_model(f\"{model_path}.h5\")\n",
        "    return model, config\n",
        "\n",
        "# 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
        "\n",
        "# 와인 데이터 읽어오기\n",
        "def load_wine_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# 와인 추천 함수\n",
        "def recommend_wines(taste_scores, wine_data):\n",
        "    recommended_wines = []\n",
        "    for idx, score in enumerate(taste_scores):\n",
        "        if score >= 0.5:  # 임계값을 조정하여 맛에 따른 추천 여부 결정\n",
        "            recommended_wines.extend(wine_data[wine_data['맛'] == taste_categories[idx]]['와인 이름'])\n",
        "    return recommended_wines\n",
        "\n",
        "# 사용자 입력에 대한 응답 생성 함수\n",
        "def generate_response(user_input, wine_data, wine_models):\n",
        "    # 사용자 입력을 BERT 모델 입력 형식에 맞게 전처리\n",
        "    inputs = tokenizer(user_input, return_tensors='tf', padding=True, truncation=True)\n",
        "\n",
        "    # 모든 와인 맛 BERT 모델을 통해 예측\n",
        "    taste_scores = []\n",
        "    for model, _ in wine_models:\n",
        "        outputs = model(inputs['input_ids'])\n",
        "        logits = outputs.logits.numpy()[0]\n",
        "        taste_scores.append(logits)\n",
        "\n",
        "    # 추천할 와인 종류 추출\n",
        "    recommended_wines_list = recommend_wines(np.array(taste_scores).mean(axis=0), wine_data)\n",
        "\n",
        "    if recommended_wines_list:\n",
        "        response = \"다음과 같은 와인들이 어울릴 것 같아요:\\n\" + \"\\n\".join(recommended_wines_list)\n",
        "    else:\n",
        "        response = \"죄송하지만, 원하시는 와인을 찾을 수 없습니다.\"\n",
        "\n",
        "    return response\n",
        "\n",
        "# 챗봇 동작\n",
        "def chatbot():\n",
        "    print(\"안녕하세요! 와인 추천 챗봇입니다. 어떤 종류의 와인을 추천 받고 싶으신가요?\")\n",
        "\n",
        "    # 와인 데이터 읽어오기\n",
        "    wine_data = load_wine_data(\"/content/test.csv\")\n",
        "\n",
        "    # 와인 맛 BERT 모델 로드\n",
        "    wine_models = []\n",
        "    for model_name in [\"model_sweet\", \"model_bitter\", \"model_sour\"]:\n",
        "        model, _ = load_wine_model(f\"/path/to/{model_name}\")\n",
        "        wine_models.append((model, _))\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"질문: \")\n",
        "\n",
        "        if user_input.lower() == '종료':\n",
        "            print(\"와인 추천 챗봇을 종료합니다.\")\n",
        "            break\n",
        "\n",
        "        response = generate_response(user_input, wine_data, wine_models)\n",
        "        print(\"답변:\", response)\n",
        "\n",
        "# 챗봇 실행\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "zDhhs3IWRTH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "WGC8YwzH0tpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이거 찐임\n",
        "import csv\n",
        "\n",
        "# 와인 데이터 읽어오기\n",
        "def load_wine_data(file_path):\n",
        "    wine_data = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            wine_name = row['WineName']\n",
        "            bitterness = float(row['Tannins_all'])\n",
        "            sweetness = float(row['Sweet_all'])\n",
        "            sourness = float(row['Acidic_all'])\n",
        "            lightness = float(row['Light_all'])\n",
        "            ex_bitterness = float(row['Tannins_ex'])\n",
        "            ex_sweetness = float(row['Sweet_ex'])\n",
        "            ex_sourness = float(row['Acidic_ex'])\n",
        "            ex_lightness = float(row['Light_ex'])\n",
        "            bg_lightness = float(row['Light_bg'])\n",
        "            bg_sourness = float(row['Acidic_bg'])\n",
        "            bg_sweetness = float(row['Sweet_bg'])\n",
        "            bg_bitterness = float(row['Tannins_bg'])\n",
        "            key_sweetness = float(row['Sweet_key'])\n",
        "            key_bitterness = float(row['Tannins_key'])\n",
        "            key_sourness = float(row['Acidic_key'])\n",
        "\n",
        "            wine_data[wine_name] = {\n",
        "                '쓴맛': bitterness,\n",
        "                '단맛': sweetness,\n",
        "                '신맛': sourness,\n",
        "                '바디감' : lightness,\n",
        "                '전문가 단맛' : ex_sweetness,\n",
        "                '전문가 쓴맛' : ex_bitterness,\n",
        "                '전문가 신맛' : ex_sourness,\n",
        "                '전문가 바디감' : ex_lightness,\n",
        "                '초심자 단맛' : bg_sweetness,\n",
        "                '초심자 쓴맛' : bg_bitterness,\n",
        "                '초심자 신맛' : bg_sourness,\n",
        "                '초심자 바디감' : bg_lightness,\n",
        "                '키워드 단맛' : key_sweetness,\n",
        "                '키워드 신맛' : key_sourness,\n",
        "                '키워드 쓴맛' : key_bitterness\n",
        "            }\n",
        "    return wine_data\n",
        "\n",
        "def recommend_wine(user_preference, wine_data, threshold=10):\n",
        "    recommended_wines = []\n",
        "    for wine_name, wine_info in wine_data.items():\n",
        "        user_sweetness = wine_info['단맛']\n",
        "        user_bitterness = wine_info['쓴맛']\n",
        "        user_sourness = wine_info['신맛']\n",
        "        user_lightness = wine_info['바디감']\n",
        "\n",
        "    if (\n",
        "          abs(user_preference['단맛']) <= threshold and\n",
        "          abs(user_preference['쓴맛']) <= threshold and\n",
        "          abs(user_preference['신맛']) <= threshold and\n",
        "          abs(user_preference['바디감']) <= threshold\n",
        "        ):\n",
        "\n",
        "            recommended_wines.append(wine_name)\n",
        "\n",
        "    return recommended_wines\n",
        "\n",
        "def chatbot():\n",
        "    file_path = '/content/WineDataset.csv'\n",
        "    wine_data = load_wine_data(file_path)\n",
        "\n",
        "    print(\"안녕하세용 전 와댕이에용 멍멍!! 종료하려면 '종료'라고 입력하세요!\")\n",
        "\n",
        "    while True:\n",
        "        print(\"와인의 맛을 알려주세요! 멍멍!!\")\n",
        "        user_sourness = int(input(\"단맛은요? (0 ~ 100 사이의 값을 입력하세요): \")) / 100\n",
        "        user_bitterness = int(input(\"쓴맛은요? (0 ~ 100 사이의 값을 입력하세요): \")) / 100\n",
        "        user_sweetness = int(input(\"신맛은요? (0 ~ 100 사이의 값을 입력하세요): \")) / 100\n",
        "        user_lightness = int(input(\"바디감은요? (0 ~ 100 사이의 값을 입력하세요): \")) / 100\n",
        "\n",
        "        threshold = 10\n",
        "\n",
        "        recommended_wines = recommend_wine({'단맛': user_sweetness, '쓴맛': user_bitterness, '신맛': user_sourness, '바디감' : user_lightness}, wine_data, threshold)\n",
        "\n",
        "        if recommended_wines:\n",
        "            print(\"와인 추천 결과에요! 마음에 들었으면 좋겠네용:\")\n",
        "            for wine in recommended_wines:\n",
        "              wine_info = wine_data[wine]\n",
        "              print(f\"이 와인을 추천해요! \\n와인 이름: {wine}\")\n",
        "              print(f\"\\n이 와인의 전체적인 맛은 다음과 같아요 \\n단맛 : {wine_info['단맛']}, 쓴맛 : {wine_info['쓴맛']}, 신맛 : {wine_info['신맛']}, 바디감 : {wine_info['바디감']}이고 \\n\\n전문가들은 이렇게 평가했어요! \\n단맛 : {wine_info['전문가 단맛']}, 쓴맛 : {wine_info['전문가 쓴맛']}, 신맛 : {wine_info['전문가 신맛']} \\n\")\n",
        "              print(\"초심자들은 이렇게 평가했어요!\")\n",
        "              print(f\"단맛 : {wine_info['초심자 단맛']}, 쓴맛 : {wine_info['초심자 쓴맛']}, 신맛 : {wine_info['초심자 신맛']} \\n\\n이거에요! 멍!\")\n",
        "\n",
        "        else:\n",
        "            print(\"해당하는 와인 정보를 찾을 수 없어요. ㅜㅜ\")\n",
        "\n",
        "        user_input = input(\"또 궁금한거 있으세요? (예/아니오): \")\n",
        "        if user_input.lower() == '아니오':\n",
        "            print(\"와댕이 이제 가볼께용! 멍!\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "nEwm6iNpK_-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9#모델 저장\n",
        "!pip install joblib"
      ],
      "metadata": {
        "id": "6kRzwJYDN1gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 챗봇 모델 저장\n",
        "def save_chatbot_model(model, file_path):\n",
        "    try:\n",
        "        joblib.dump(model, file_path)\n",
        "        print(\"챗봇 모델이 성공적으로 저장되었습니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"챗봇 모델 저장 중 오류 발생: {e}\")\n",
        "\n",
        "# 챗봇 모델 로드\n",
        "def load_chatbot_model(file_path):\n",
        "    try:\n",
        "        model = joblib.load(file_path)\n",
        "        print(\"챗봇 모델이 성공적으로 로드되었습니다.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"챗봇 모델 로드 중 오류 발생: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "szhVOgipN_no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 챗봇 모델 저장\n",
        "chatbot_model = chatbot  # chatbot 함수를 저장하려면 chatbot_model = chatbot 대신 사용\n",
        "save_chatbot_model(chatbot_model, 'wadeang_model.joblib')\n",
        "\n",
        "# 챗봇 모델 로드\n",
        "loaded_chatbot_model = load_chatbot_model('chatbot_model.joblib')\n",
        "\n",
        "# 챗봇 모델 사용\n",
        "if loaded_chatbot_model:\n",
        "    loaded_chatbot_model()\n"
      ],
      "metadata": {
        "id": "u0TLgwdUOFOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOKyPegnOKGe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}