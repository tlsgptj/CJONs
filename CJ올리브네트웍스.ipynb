{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1L7HzeRvttzohOeuoRPhmEE1GkBZcBRub",
      "authorship_tag": "ABX9TyNXqQUTrYqv/PnyUS4anf76",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlsgptj/CJONs/blob/main2/CJ%EC%98%AC%EB%A6%AC%EB%B8%8C%EB%84%A4%ED%8A%B8%EC%9B%8D%EC%8A%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqBO_6dlzi20"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os, sys\n",
        "import urllib.parse\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.vivino.com/obsidian-ridge-estate-grown-cabernet-sauvignon/w/2165446?ref=nav-search#all_reviews'\n",
        "response = requests.get(url)\n",
        "html = response.text"
      ],
      "metadata": {
        "id": "V8bdwzhAzuLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "u18IOJ742FSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "component_content = soup.select('div',class_=\"allReviews__reviews--EpUem\")\n",
        "print(len(component_content))\n",
        "for review in enumerate(component_content):\n",
        "  review = review.select('span.communityReview__reviewText--2bfLj')\n",
        "  print(review)"
      ],
      "metadata": {
        "id": "vQntOITZ2Mt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in enumerate(component_content):\n",
        "  review = review.select('span.communityReview__reviewText--2bfLj')\n",
        "  print(review)\n"
      ],
      "metadata": {
        "id": "WWnDNvlKFKFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, LSTM"
      ],
      "metadata": {
        "id": "Zx1AKR_PNMBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "Hq1zyfNR5UO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "wVrN2d__5g5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordcloud 사용 및 단어 토큰화\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "epA0DSz9621t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/스파클링 1.csv\")"
      ],
      "metadata": {
        "id": "FF2ihgE17MQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "lWAPqOuj-jdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "rpI05Vwu-kfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D"
      ],
      "metadata": {
        "id": "1D-xM3KE-vxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pad_sequences"
      ],
      "metadata": {
        "id": "onVD5KLo_GF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "A3sQHoVc_RYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "L_ZqqGyJBe1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "id": "GPWMIOvUBhNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "smV8GaPkBqmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas tensorflow"
      ],
      "metadata": {
        "id": "BCAK0cJtEczm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "NA8J1CFMrox9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/스파클링 1.csv')"
      ],
      "metadata": {
        "id": "Vch3ViWzrw0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "xtzb8Hyqr6xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['리뷰']"
      ],
      "metadata": {
        "id": "2QbHOYbmr7j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "id": "7zCca2OksBP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data['리뷰']"
      ],
      "metadata": {
        "id": "3BnIvbFIsC0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "9zGTy4Q6sGZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터 전처리\n",
        "max_features = 20000  # 단어 사전의 크기\n",
        "maxlen = 80  # 시퀀스의 최대 길이\n",
        "batch_size = 32\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('단어 사전 크기:', len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# 라벨 벡터 변환\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "# LSTM 모델 구축\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# 모델 훈련\n",
        "print('모델 훈련 시작...')\n",
        "model.fit(data, labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "score, acc = model.evaluate(data, labels, batch_size=batch_size)\n",
        "print('테스트 정확도:', acc)"
      ],
      "metadata": {
        "id": "0uFU3vpvsIME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"/content/2_대화체.xlsx\")"
      ],
      "metadata": {
        "id": "0XAJe1rJsRCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "HsNAH6WNZ9Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"대분류\", \"소분류\", \"상황\", \"Set Nr.\", \"발화자\"])"
      ],
      "metadata": {
        "id": "HaV6kG0XbESH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "cpTI15mcbZ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"번역문\"] = df[\"번역문\"].apply(lambda x: word_tokenize(x))"
      ],
      "metadata": {
        "id": "jF_40qSybacw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "lJC14kJNbzIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"번역문\"]"
      ],
      "metadata": {
        "id": "KyAaegmPb2Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Set up the word cloud parameters\n",
        "wordcloud = WordCloud(width=800, height=400,\n",
        "                      background_color='white',\n",
        "                      colormap='viridis',\n",
        "                      min_font_size=10,\n",
        "                      max_words=200,\n",
        "                      collocations=False)"
      ],
      "metadata": {
        "id": "JBynNEixcBgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = df[\"번역문\"].sum()\n",
        "word_string = \" \".join(word_list)"
      ],
      "metadata": {
        "id": "4nxM3pvqcHAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud.generate(word_string)\n",
        "\n",
        "# Display the word cloud using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CVK_nmhncK9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "V-aKTXYihVjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "G_uvmaknhjSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/2_대화체.xlsx\")"
      ],
      "metadata": {
        "id": "g5oMnMJohzy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"대분류\", \"소분류\", \"상황\", \"Set Nr.\", \"발화자\"])"
      ],
      "metadata": {
        "id": "es0U3mXzicoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "import sentencepiece\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# 번역에 사용할 BERT 모델과 tokenizer를 로드합니다.\n",
        "translator_model_name = \"Helsinki-NLP/opus-mt-ko-en\"  # 한국어-영어 번역용 BERT 모델\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
        "\n",
        "# 챗봇에 사용할 BERT 모델과 tokenizer를 로드합니다.\n",
        "chatbot_model_name = \"bert-base-multilingual-cased\"  # 다국어 BERT 모델\n",
        "chatbot_tokenizer = AutoTokenizer.from_pretrained(chatbot_model_name)\n",
        "chatbot_model = AutoModelForSequenceClassification.from_pretrained(chatbot_model_name)"
      ],
      "metadata": {
        "id": "5-CQXM6yiiHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "H5OcZc8SilbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "oHdy6-Rmns0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Replace 'your_model_name' with the name of the model you want to use\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Now you should be able to use the tokenizer without errors\n"
      ],
      "metadata": {
        "id": "rr30cV2kiwpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip list | grep sentencepiece"
      ],
      "metadata": {
        "id": "YIg4PrxVi5B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_korean_to_english(text):\n",
        "    inputs = translator_tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = translator_model(**inputs)\n",
        "    translated_text = translator_tokenizer.decode(outputs.logits.argmax(dim=-1)[0])\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "JZdMzHzckstH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(input_text):\n",
        "    inputs = chatbot_tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = chatbot_model(**inputs)\n",
        "    response = chatbot_tokenizer.decode(outputs.logits.argmax(dim=-1)[0])\n",
        "    return response"
      ],
      "metadata": {
        "id": "S1gF2Y1eoAPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [\n",
        "    (\"What is wine?\",\"Wine is an alcoholic beverage made from fermented grapes or other fruits.\"),\n",
        "    (\"What are the different types of wine?\",\"There are several types of wine, including red, white, rosé, sparkling, and dessert wines.\"),\n",
        "    (\"How is wine made?\", \"Wine is made through the fermentation of grape juice, where yeast converts sugar into alcohol.\"),\n",
        "    (\"What is the difference between red and white wine?\", \"Red wine is made from red or black grapes and is fermented with the grape skins, while white wine is made from green or yellow grapes and is fermented without the skins.\"),\n",
        "    (\"How should I store wine at home?\",\"Wine should be stored in a cool, dark place, preferably on its side to keep the cork moist.\"),\n",
        "    (\"What are tannins in wine?\", \"Tannins are natural compounds found in grape skins, seeds, and stems, which give wine its astringency and bitterness.\"),\n",
        "    (\"What is the ideal serving temperature for red wine?\", \"Red wine is typically served at room temperature, around 60-65°F (15-18°C).\"),\n",
        "    (\"How long can I keep an opened bottle of wine?\",\"Once opened, wine can be kept for a few days to a week, depending on the type. Red wines generally last longer than white wines.\"),\n",
        "    (\"What is the best wine to pair with steak?\",\"A bold red wine, such as Cabernet Sauvignon or Malbec, pairs well with steak.\"),\n",
        "    (\"What is the difference between dry and sweet wine?\",\"Dry wine has very little residual sugar, while sweet wine has higher sugar content.\"),\n",
        "    (\"What is the difference between Cabernet Sauvignon and Merlot?\", \"Cabernet Sauvignon is a full-bodied red wine with bold tannins, while Merlot is softer and more approachable with a medium body.\"),\n",
        "    (\"What is the best wine to pair with cheese?\", \"Red wines like Cabernet Sauvignon, Merlot, or Syrah/Shiraz pair well with hard cheeses, while white wines like Chardonnay or Sauvignon Blanc go well with soft cheeses.\"),\n",
        "    (\"Can I age sparkling wine?\",\"Most sparkling wines are meant to be consumed young and fresh, and aging may not improve their taste.\"),\n",
        "    (\"What is the difference between a wine's aroma and its nose?\",\"The aroma refers to the overall smell of the wine, while the nose specifically refers to the smell of the wine in the glass.\"),\n",
        "    (\"Can I use wine as a marinade?\",\"Yes, wine can be used as a marinade to add flavor and tenderize meat.\"),\n",
        "    (\"What is the best wine to pair with roast chicken?\",\"Chardonnay or Pinot Noir pair well with roast chicken.\"),\n",
        "    (\"How do I clean wine glasses?\",\"To clean wine glasses, hand wash them with warm water and mild detergent, and let them air dry to avoid leaving streaks or residue.\"),\n",
        "    (\"What is the best wine to pair with sushi?\",\"A dry Riesling or a sparkling wine like Champagne go well with sushi.\"),\n",
        "    (\"What is the difference between a wine's aroma and its taste?\",\"The aroma refers to the smell of the wine, while the taste includes the flavor and mouthfeel experienced on the palate.\"),\n",
        "    (\"Can I age white wine?\", \"Some high-quality white wines can be aged, but most white wines are meant to be consumed within a few years of purchase.\")\n",
        "\n",
        "]\n",
        "\n",
        "# DataFrame으로 변환\n",
        "combined_df = pd.DataFrame(data, columns=[\"Question\", \"Answer\"])\n",
        "\n",
        "# 결과 출력\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "8uOYo3Imvifu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "# BERT 챗봇 모델과 tokenizer 로드\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# 와인 관련 문답 데이터를 DataFrame에서 가져옵니다.\n",
        "# 여기서는 앞서 만든 combined_df를 사용합니다.\n",
        "# 이전 코드에서 combined_df를 생성한 뒤 여기에 계속 질문과 답변을 추가할 수 있습니다.\n",
        "# combined_df = pd.concat([combined_df, new_df], ignore_index=True)  # new_df에 새로운 질문과 답변이 포함되어 있다면 추가\n",
        "\n",
        "def generate_answer(question):\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# BERT 챗봇으로 답변 생성\n",
        "for index, row in combined_df.iterrows():\n",
        "    question = row[\"Question\"]\n",
        "    answer = generate_answer(question)\n",
        "    combined_df.at[index, \"BERT_Answer\"] = answer\n",
        "\n",
        "# 결과 출력\n",
        "print(combined_df[[\"Question\", \"BERT_Answer\"]])\n"
      ],
      "metadata": {
        "id": "QFbt5QUPxgFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.DataFrame(df, columns=[\"Question\", \"Answer\"])"
      ],
      "metadata": {
        "id": "owrbxIMXx3Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "# BERT 챗봇 모델과 tokenizer 로드\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# 모델과 tokenizer를 디렉토리에 저장\n",
        "model_dir = \"saved_model\"  # 저장할 디렉토리 이름\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "# 저장된 모델과 tokenizer 로드\n",
        "loaded_model = AutoModelForMaskedLM.from_pretrained(model_dir)\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# BERT 챗봇으로 답변 생성\n",
        "def generate_answer(question):\n",
        "    inputs = loaded_tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model.generate(**inputs)\n",
        "    answer = loaded_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "wY3mjgFLyam9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 tokenizer를 로드합니다. (앞서 저장한 디렉토리 이름인 'saved_model'을 사용합니다.)\n",
        "loaded_model = AutoModelForMaskedLM.from_pretrained('saved_model')\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained('saved_model')\n",
        "\n",
        "# BERT 챗봇으로 답변 생성하는 함수\n",
        "def generate_answer(question):\n",
        "    inputs = loaded_tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model.generate(**inputs)\n",
        "    answer = loaded_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# 테스트 문장\n",
        "test_question = \"What is the difference between red and white wine?\"\n",
        "\n",
        "# BERT 챗봇으로 테스트 문장에 대한 답변 생성\n",
        "answer = generate_answer(test_question)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"질문:\", test_question)\n",
        "print(\"답변:\", answer)"
      ],
      "metadata": {
        "id": "y8ZDEoofy5jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 tokenizer를 로드합니다. (앞서 저장한 디렉토리 이름인 'saved_model'을 사용합니다.)\n",
        "loaded_model = AutoModelForMaskedLM.from_pretrained('saved_model')\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained('saved_model')\n",
        "\n",
        "# 질문과 답변을 매칭시킬 딕셔너리 생성\n",
        "qa_mapping = {}\n",
        "\n",
        "# BERT 챗봇으로 답변 생성하는 함수\n",
        "def generate_answer(question):\n",
        "    inputs = loaded_tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model.generate(**inputs)\n",
        "    answer = loaded_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# 질문과 답변을 매칭\n",
        "for index, row in combined_df.iterrows():\n",
        "    question = row[\"Question\"]\n",
        "    answer = generate_answer(question)\n",
        "    qa_mapping[question] = answer\n",
        "\n",
        "# 결과 출력\n",
        "for question, answer in qa_mapping.items():\n",
        "    print(\"질문:\", question)\n",
        "    print(\"답변:\", answer)\n",
        "    print()"
      ],
      "metadata": {
        "id": "lIHRNWQqzie0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 먼저 BERT 챗봇 모델과 토크나이저를 불러옵니다 (이전에 정의한 것으로 가정합니다)\n",
        "translator_model_name = \"bert-base-multilingual-cased\"  # 한국어-영어 번역용 BERT 모델\n",
        "translator_tokenizer = AutoTokenizer.from_pretrained(translator_model_name)\n",
        "translator_model = AutoModelForSequenceClassification.from_pretrained(translator_model_name)\n",
        "\n",
        "# 새로운 열을 추가할 데이터프레임 복사본을 만듭니다\n",
        "combined_df_with_bert_answer = combined_df.copy()\n",
        "\n",
        "# BERT 챗봇을 사용하여 답변 생성하고, 새로운 열에 저장합니다\n",
        "for index, row in combined_df_with_bert_answer.iterrows():\n",
        "    question = row[\"Question\"]\n",
        "    answer = generate_answer(row[\"Answer\"])\n",
        "    combined_df_with_bert_answer.at[index, \"BERT_Answer\"] = answer\n",
        "\n",
        "# 생성된 데이터프레임 확인\n",
        "print(combined_df_with_bert_answer)"
      ],
      "metadata": {
        "id": "MkEKs4Du0Whl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "#모델 불러오기\n",
        "translator_model_name = \"bert-base-multilingual-cased\"\n",
        "translator_tokenizer = AutoTokenizer.from_pretrained(translator_model_name)\n",
        "translator_model = AutoModelForSequenceClassification.from_pretrained(translator_model_name)\n",
        "\n",
        "# 새로운 열을 추가할 데이터프레임 복사본을 만듭니다\n",
        "combined_df_with_bert_answer = combined_df.copy()\n",
        "\n",
        "# BERT 챗봇을 사용하여 답변 생성하고, 새로운 열에 저장합니다\n",
        "for index, row in combined_df_with_bert_answer.iterrows():\n",
        "    question = row[\"Question\"]\n",
        "    answer = generate_answer(row[\"Answer\"])\n",
        "    combined_df_with_bert_answer.at[index, \"BERT_Answer\"] = answer\n",
        "\n",
        "# 모델 저장\n",
        "output_model_dir = \"saved_bert_chatbot_model\"\n",
        "translator_model.save_pretrained(output_model_dir)\n",
        "translator_tokenizer.save_pretrained(output_model_dir)\n",
        "\n",
        "# 생성된 데이터프레임 확인\n",
        "print(combined_df_with_bert_answer)"
      ],
      "metadata": {
        "id": "sl_TA1g98Pkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# 모델과 토크나이저 불러오기\n",
        "output_model_dir = \"saved_bert_chatbot_model\"\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(output_model_dir)\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(output_model_dir)\n",
        "\n",
        "# 예시로 답변 생성\n",
        "question = 'What is wine?'\n",
        "inputs = loaded_tokenizer(question, return_tensors=\"pt\")\n",
        "outputs = loaded_model(**inputs)\n",
        "answer_start = torch.argmax(outputs.logits)\n",
        "answer = loaded_tokenizer.decode(inputs[\"input_ids\"][0, answer_start:])\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "id": "ZHYqQF156zh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# 데이터 로딩\n",
        "data = [(\"What is wine?\", \"Wine is an alcoholic beverage made from fermented grapes or other fruits.\", 0),\n",
        "(\"What are the different types of wine?\", \"There are several types of wine, including red, white, rosé, sparkling, and dessert wines.\", 1),\n",
        "(\"How is wine made?\", \"Wine is made through the fermentation of grape juice, where yeast converts sugar into alcohol.\", 2),\n",
        "(\"What is the difference between red and white wine?\", \"Red wine is made from red or black grapes and is fermented with the grape skins, while white wine is made from green or yellow grapes and is fermented without the skins.\", 3),\n",
        "(\"How should I store wine at home?\", \"Wine should be stored in a cool, dark place, preferably on its side to keep the cork moist.\", 4),\n",
        "(\"What are tannins in wine?\", \"Tannins are natural compounds found in grape skins, seeds, and stems, which give wine its astringency and bitterness.\", 5),\n",
        "(\"What is the ideal serving temperature for red wine?\", \"Red wine is typically served at room temperature, around 60-65°F (15-18°C).\", 6),\n",
        "(\"How long can I keep an opened bottle of wine?\", \"Once opened, wine can be kept for a few days to a week, depending on the type. Red wines generally last longer than white wines.\", 7),\n",
        "(\"What is the best wine to pair with steak?\", \"A bold red wine, such as Cabernet Sauvignon or Malbec, pairs well with steak.\", 8),\n",
        "(\"What is the difference between dry and sweet wine?\", \"Dry wine has very little residual sugar, while sweet wine has higher sugar content.\", 9),\n",
        "(\"What is the difference between Cabernet Sauvignon and Merlot?\", \"Cabernet Sauvignon is a full-bodied red wine with bold tannins, while Merlot is softer and more approachable with a medium body.\", 10),\n",
        "(\"What is the best wine to pair with cheese?\", \"Red wines like Cabernet Sauvignon, Merlot, or Syrah/Shiraz pair well with hard cheeses, while white wines like Chardonnay or Sauvignon Blanc go well with soft cheeses.\", 11),\n",
        "(\"Can I age sparkling wine?\", \"Most sparkling wines are meant to be consumed young and fresh, and aging may not improve their taste.\", 12),\n",
        "(\"What is the difference between a wine's aroma and its nose?\", \"The aroma refers to the overall smell of the wine, while the nose specifically refers to the smell of the wine in the glass.\", 13),\n",
        "(\"Can I use wine as a marinade?\", \"Yes, wine can be used as a marinade to add flavor and tenderize meat.\", 14),\n",
        "(\"What is the best wine to pair with roast chicken?\", \"Chardonnay or Pinot Noir pair well with roast chicken.\", 15),\n",
        "(\"How do I clean wine glasses?\", \"To clean wine glasses, hand wash them with warm water and mild detergent, and let them air dry to avoid leaving streaks or residue.\", 16),\n",
        "(\"What is the best wine to pair with sushi?\", \"A dry Riesling or a sparkling wine like Champagne go well with sushi.\", 17),\n",
        "(\"What is the difference between a wine's aroma and its taste?\", \"The aroma refers to the smell of the wine, while the taste includes the flavor and mouthfeel experienced on the palate.\", 18),\n",
        "(\"Can I age white wine?\", \"Some high-quality white wines can be aged, but most white wines are meant to be consumed within a few years of purchase.\", 19),\n",
        "(\"Please describe the taste of wine.\", \"Wine has rich fruit flavors and smooth tannins.\", 20),\n",
        "(\"How does wine's acidity feel?\", \"Wine's acidity is tart and refreshing.\", 20),\n",
        "(\"What is tannin?\", \"Tannin is a component in wine that gives it a bitter taste, often found in grape skins or seeds.\", 20),\n",
        "(\"How is the sweetness of wine determined?\", \"The sweetness of wine is determined by the amount of residual sugar it contains.\", 20),\n",
        "(\"Which wine pairs well with meat?\", \"Red wine pairs well with meat.\", 20),\n",
        "(\"What does 'body' mean in wine?\", \"The body of wine refers to its weight or texture, ranging from light-bodied to full-bodied.\", 20),\n",
        "(\"Why does wine taste bitter?\", \"Wine can taste bitter due to the presence of tannins.\", 20),\n",
        "(\"Does higher alcohol content in wine affect its taste?\", \"Higher alcohol content in wine can make it warmer and more intense in flavor.\", 20),\n",
        "(\"Does wine taste better with age?\", \"Some wines can improve with age, gaining more complexity and subtle flavors.\", 20),\n",
        "(\"Is it okay to drink wine warm?\", \"Wine is generally best served slightly chilled.\", 20),\n",
        "(\"Which is better, white wine or red wine?\", \"It depends on individual preferences, but red wines are usually bolder and more complex.\", 20),\n",
        "(\"How do you decant wine?\", \"Decanting involves transferring wine to a separate container, like a decanter or a glass pitcher.\", 20),\n",
        "(\"Why is decanting wine beneficial?\", \"Decanting can soften the wine's acidity and tannins, enhancing its flavors.\", 20),\n",
        "(\"Does the order of wine tasting matter?\", \"The order of wine tasting is important to fully appreciate its characteristics.\", 20),\n",
        "(\"At what temperature should wine be served?\", \"White wine should be served slightly chilled, while red wine can be served at slightly warmer temperatures.\", 20),\n",
        "(\"How should you taste wine to fully experience its flavor?\", \"Before sipping, try to smell the wine and then take a small sip to savor the taste.\", 20),\n",
        "(\"Can you suggest wine and food pairings?\", \"Wines with strong fruit flavors go well with seafood, while red wine pairs nicely with steak.\", 20),\n",
        "(\"How long can you store wine?\", \"The storage time varies depending on the type of wine, but generally, 2-10 years of aging is common.\", 20),\n",
        "(\"Why is aging wine in oak barrels preferred?\", \"Aging wine in oak barrels adds flavors like vanilla and enhances its smoothness.\", 20),\n",
        "(\"How is sweetness created in wine?\", \"Sweetness in wine is created when there is residual sugar in the wine after fermentat\", 20)]  # 라벨링한 데이터를 리스트 형태로 저장\n",
        "\n",
        "# BERT 토크나이저\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 입력 문장과 라벨을 토치 데이터셋으로 변환\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.data[idx][0]\n",
        "        label = self.data[idx][2]\n",
        "\n",
        "        inputs = tokenizer(input_text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "        label = torch.tensor(int(label))\n",
        "\n",
        "        return inputs, label\n",
        "\n",
        "# 데이터셋 준비\n",
        "wine_dataset = WineDataset(data)\n",
        "train_loader = DataLoader(wine_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "NUM_LABELS = 21\n",
        "NUM_EPOCHS = 21\n",
        "\n",
        "# BERT 모델 불러오기\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUM_LABELS)\n",
        "\n",
        "# Optimizer 설정 및 학습\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "labels = labels.to(device)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    inputs, labels = zip(*batch)  # tuple을 풀어줍니다.\n",
        "    inputs = {k: torch.cat([item[k] for item in inputs], dim=0) for k in inputs[0]}  # batch 단위로 concatenate\n",
        "    labels = torch.stack(labels, dim=0)  # batch 단위로 stack\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "train_loader = DataLoader(wine_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "# 학습된 모델을 이용하여 챗봇 구현\n",
        "conversation=[]\n",
        "def wine_chatbot(question):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(question, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_label = torch.argmax(logits).item()\n",
        "\n",
        "    if predicted_label < 0 or predicted_label >= NUM_LABELS:\n",
        "        return \"I apologize, but I couldn't find an answer to that question.\"\n",
        "\n",
        "    # 대화 기록 저장\n",
        "    conversation.append((question, data[predicted_label][1]))\n",
        "\n",
        "    return data[predicted_label][1]\n",
        "\n",
        "# 대화 기록을 출력하는 함수\n",
        "def print_conversation():\n",
        "    print(\"대화 기록:\")\n",
        "    for i, (user_input, bot_response) in enumerate(conversation):\n",
        "        print(f\"{i + 1}. 사용자: {user_input}\")\n",
        "        print(f\"   챗봇: {bot_response}\")\n",
        "        print()\n",
        "\n",
        "# 챗봇 테스트\n",
        "question = \"What is the difference between red and white wine?\"\n",
        "predicted_label = wine_chatbot(question)\n",
        "print(\"Predicted label:\", predicted_label)"
      ],
      "metadata": {
        "id": "gRr2H0I3991T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 저장\n",
        "torch.save(model.state_dict(), 'wine_chatbot_model.pt')"
      ],
      "metadata": {
        "id": "CAFz0ASVFT6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# BERT 토크나이저\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "NUM_LABELS = 20\n",
        "\n",
        "# 학습된 모델 불러오기\n",
        "loaded_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUM_LABELS)\n",
        "loaded_model.load_state_dict(torch.load('wine_chatbot_model.pt'))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "loaded_model.to(device)\n",
        "\n",
        "def wine_chatbot(question):\n",
        "    loaded_model.eval()\n",
        "    inputs = tokenizer(question, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_label = torch.argmax(logits).item()\n",
        "    return predicted_label\n",
        "\n",
        "# 테스트 문답 형식으로 챗봇 테스트\n",
        "while True:\n",
        "    question = input(\"질문을 입력하세요 (종료를 원하면 '종료'를 입력하세요): \")\n",
        "    if question == '종료':\n",
        "        print(\"챗봇 테스트를 종료합니다.\")\n",
        "        break\n",
        "    predicted_label = wine_chatbot(question)\n",
        "    print(\"예측된 라벨:\", predicted_label)\n",
        "    answer = data[predicted_label][1]\n",
        "    print(\"답변:\", answer)"
      ],
      "metadata": {
        "id": "OQsLrWzxJimN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# 와인 BERT 모델 로드\n",
        "wine_bert_model_name = \"path_to_pretrained_wine_bert\"  # 와인 BERT 모델의 경로나 이름\n",
        "wine_tokenizer = BertTokenizer.from_pretrained(wine_bert_model_name)\n",
        "wine_model = BertModel.from_pretrained(wine_bert_model_name)\n",
        "\n",
        "# 챗봇 BERT 모델 로드\n",
        "chatbot_bert_model_name = \"path_to_pretrained_chatbot_bert\"  # 챗봇 BERT 모델의 경로나 이름\n",
        "chatbot_tokenizer = BertTokenizer.from_pretrained(chatbot_bert_model_name)\n",
        "chatbot_model = BertModel.from_pretrained(chatbot_bert_model_name)\n",
        "\n",
        "# 챗봇 BERT에 와인 BERT 삽입\n",
        "# 예를 들어, 챗봇 BERT의 첫 번째 레이어에 와인 BERT를 삽입하겠습니다.\n",
        "chatbot_model.bert.embeddings.word_embeddings.weight = wine_model.bert.embeddings.word_embeddings.weight\n",
        "\n",
        "# 이제 챗봇 BERT를 사용하여 대화를 수행할 수 있습니다.\n",
        "input_text = \"와인 추천해줘\"\n",
        "inputs = chatbot_tokenizer(input_text, return_tensors=\"pt\")\n",
        "outputs = chatbot_model(**inputs)\n",
        "# 결과로 나온 outputs를 해석하여 적절한 답변을 생성할 수 있습니다.\n",
        "\n",
        "# 이후 모델을 훈련하고 세부적인 파라미터 조정 등을 진행해야 합니다.\n"
      ],
      "metadata": {
        "id": "8FqGgqPnKSJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "\n",
        "# BERT 모델과 토크나이저 로드\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "def recommend_wine(intent):\n",
        "    if intent == \"과일향이 강한 와인을 찾아줘\":\n",
        "        return \"~와인을 추천해드립니다!\"\n",
        "    elif intent == \"탄닌감이 높은 와인을 추천해줘\":\n",
        "        return \"~와인을 추천해드립니다!\"\n",
        "    else:\n",
        "        return \"죄송합니다, 그 질문을 이해하지 못했어요. 좀 더 구체적으로 설명해주시겠어요?\"\n",
        "\n",
        "# 사용자 입력 처리\n",
        "user_input = \"탄닌감이 높은 와인을 추천해줘\"\n",
        "intent = user_input\n",
        "\n",
        "# 의도 파악하여 적절한 답변 제공\n",
        "answer = recommend_wine(intent)\n",
        "print(f\"A: {answer}\")\n"
      ],
      "metadata": {
        "id": "zBahydApBFyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "\n",
        "# BERT 모델과 토크나이저 로드\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "def recommend_wine(style):\n",
        "    return \"~와인을 추천해드립니다!\"\n",
        "\n",
        "# 사용자 입력 처리\n",
        "user_input = \"와인 추천해줘\"\n",
        "intent = user_input\n",
        "\n",
        "if intent == \"와인 추천해줘\":\n",
        "    # 추가 정보 요청\n",
        "    print(\"과일향이 강한 와인이나, 탄닌감이 높은 와인 중 어떤 스타일이 원하시나요?\")\n",
        "else:\n",
        "    # 스타일에 따라 와인 추천\n",
        "    style = intent\n",
        "    answer = recommend_wine(style)\n",
        "    print(f\"A: {answer}\")\n"
      ],
      "metadata": {
        "id": "0IlnqtCrBHLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "\n",
        "# BERT 모델과 토크나이저 로드\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# 대화 기록 저장 리스트\n",
        "conversation = []\n",
        "\n",
        "def recommend_wine(intent):\n",
        "    if intent == \"과일향이 강한 와인을 찾아줘\":\n",
        "        return \"~와인을 추천해드립니다!\"\n",
        "    elif intent == \"탄닌감이 높은 와인을 추천해줘\":\n",
        "        return \"~와인을 추천해드립니다!\"\n",
        "    else:\n",
        "        return \"죄송합니다, 그 질문을 이해하지 못했어요. 좀 더 구체적으로 설명해주시겠어요?\"\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"사용자: \")\n",
        "    conversation.append(user_input)\n",
        "\n",
        "    # 대화 기록 중 가장 최근 2개의 대화를 의도 파악에 사용\n",
        "    if len(conversation) >= 2:\n",
        "        intent = conversation[-2]\n",
        "    else:\n",
        "        intent = user_input\n",
        "\n",
        "    # 의도 파악하여 적절한 답변 제공\n",
        "    answer = recommend_wine(intent)\n",
        "    print(f\"챗봇: {answer}\")\n"
      ],
      "metadata": {
        "id": "VjcuYSddBJHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "\n",
        "# BERT 모델과 토크나이저 로드\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "def recommend_wine(intent):\n",
        "    if intent == \"과일향이 강한 와인을 찾아줘\":\n",
        "        return \"~와인을 추천해드립니다!\"\n",
        "    elif intent == \"탄닌감이 높은 와인을 추천해줘\":\n",
        "        return \"~와인을 추천해드립니다!\"\n",
        "    else:\n",
        "        return \"죄송합니다, 그 질문을 이해하지 못했어요. 좀 더 구체적으로 설명해주시겠어요?\"\n",
        "\n",
        "# 사용자 입력 처리\n",
        "user_input = \"나한테 맞는 와인은 뭘까요?\"\n",
        "intent = user_input\n",
        "\n",
        "# 의도 파악하여 적절한 답변 제공\n",
        "try:\n",
        "    answer = recommend_wine(intent)\n",
        "except:\n",
        "    answer = \"죄송합니다, 예상치 못한 오류가 발생했습니다. 다시 시도해주세요.\"\n",
        "print(f\"A: {answer}\")\n"
      ],
      "metadata": {
        "id": "0WrxiFwvBL8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#와인 BERT 감정분석\n",
        "#맛지표 라이트랑 볼드"
      ],
      "metadata": {
        "id": "VmTdEjt6g-VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "oWY4JxAz23YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀 파일 읽어오기\n",
        "file_path = '/content/Bodega Norton Malbec D.O.csv'\n",
        "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
        "\n",
        "# 괄호 안에 있는 부분 나누기\n",
        "df['Ratings'] = df['Name'].str.extract(r'\\((\\d+)\\sratings\\)')\n",
        "df['Name'] = df['Name'].str.replace(r'\\s\\(\\d+\\sratings\\)', '')\n",
        "\n",
        "# 결과 출력\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "5uj655PN3FBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Bodega Norton Malbec D.O.csv\")"
      ],
      "metadata": {
        "id": "yKJtsldS3K33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "iL_6Q3Pz30bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "1eTt9AJ631BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Set up the word cloud parameters\n",
        "wordcloud = WordCloud(width=800, height=400,\n",
        "                      background_color='white',\n",
        "                      colormap='viridis',\n",
        "                      min_font_size=10,\n",
        "                      max_words=200,\n",
        "                      collocations=False)"
      ],
      "metadata": {
        "id": "_GKy53rJ38DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "df[\"후기\"] = df[\"후기\"].apply(lambda x: word_tokenize(x))"
      ],
      "metadata": {
        "id": "tfzWs-Ct4BXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "QSyHVbrG4HMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = df[\"후기\"].sum()\n",
        "word_string = \" \".join(word_list)"
      ],
      "metadata": {
        "id": "V4M7Mahq4K9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the word cloud from the concatenated string\n",
        "wordcloud.generate(word_string)\n",
        "\n",
        "# Display the word cloud using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pLWNFIzU4daj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [\n",
        "    \"wine\", \"Malbec\", \"fruit\", \"plum\", \"long\", \"palate\", \"still\", \"Amazing\", \"month\", \"drink\", \"current\", \"hint\", \"strong\", \"year\", \"well\", \"round\", \"time\", \"Wow\", \"really\"\n",
        "]"
      ],
      "metadata": {
        "id": "fQ-bJ4xm4ufa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "import re"
      ],
      "metadata": {
        "id": "ON3Vuss1Ht_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 불용어 리스트를 가져옵니다.\n",
        "stopwords = [\"wine\", \"Malbec\", \"fruit\", \"plum\", \"long\", \"palate\", \"still\", \"Amazing\", \"month\", \"drink\", \"current\", \"hint\", \"strong\", \"year\", \"well\", \"round\", \"time\", \"Wow\", \"really\"\n",
        "]\n",
        "\n",
        "# 단어 리스트를 공백을 기준으로 토큰화합니다.\n",
        "all_tokens = word_tokenize(word_string)\n",
        "\n",
        "# 모든 토큰을 소문자로 변환하고 불용어를 제거하여 단어의 빈도를 계산합니다.\n",
        "word_freq = Counter(token.lower() for token in all_tokens if token.lower() not in stopwords)\n",
        "\n",
        "# 워드 클라우드 생성\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
        "\n",
        "# 워드 클라우드를 matplotlib로 출력합니다.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qZZiiQbbH7Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [\n",
        "    \"and\", \"the\", \"of\", \"with\", \"malbec\", \"a\", \".\", \"finish\", \"i\", \"but\", \"had\", \"uco\", \"yet\", \"have\", \"was\", \"wow\", \"glass\", \"wines\"\n",
        "]"
      ],
      "metadata": {
        "id": "-3TCuVCfINrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 불용어 리스트를 가져옵니다.\n",
        "stopwords = [\n",
        "    \"and\", \"the\", \"of\", \"with\", \"malbec\", \"a\", \".\", \"finish\", \"i\", \"but\", \"had\", \"uco\", \"yet\", \"have\", \"was\", \"wow\", \"glass\", \"wines\"\n",
        "]\n",
        "\n",
        "# 단어 리스트를 공백을 기준으로 토큰화합니다.\n",
        "all_tokens = word_tokenize(word_string)\n",
        "\n",
        "# 모든 토큰을 소문자로 변환하고 불용어를 제거하여 단어의 빈도를 계산합니다.\n",
        "word_freq = Counter(token.lower() for token in all_tokens if token.lower() not in stopwords)\n",
        "\n",
        "# 워드 클라우드 생성\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
        "\n",
        "# 워드 클라우드를 matplotlib로 출력합니다.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AysHcvtWJMYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 불용어 리스트를 가져옵니다.\n",
        "stopwords = [\n",
        "    \"in\", \"this\", \"is\", \"it\", \",\", \"!\", \"for\", \"full\", \"to\", \"notes\", \"from\", \"an\", \"bottle\", \"just\", \"more\", \"has\", \"be\",\n",
        "    \"and\", \"the\", \"of\", \"with\", \"malbec\", \"a\", \".\", \"finish\", \"i\", \"but\", \"had\", \"uco\", \"yet\", \"have\", \"was\", \"wow\", \"glass\", \"wines\",\n",
        "    \"wine\", \"Malbec\", \"fruit\", \"plum\", \"long\", \"palate\", \"still\", \"Amazing\", \"month\", \"drink\", \"current\", \"hint\", \"strong\", \"year\", \"well\", \"round\", \"time\", \"Wow\", \"really\",\n",
        "    \"(\", \")\", \"at\", \"%\", \"one\", \"so\", \"all\", \"are\", \"not\", \"what\", \"big\", \"will\", \"you\", \"by\", \"18\", \"12\", \"deep\", \"on\", \"as\", \"high\", \"structure\", \"need\", \"my\", \"de\", \"ever\",\n",
        "    \"almost\", \"little\", \"fruits\", \"very\", \"red\", \"that\", \"complex\", \"every\", \"nose\", \"tones\", \"its\", \"than\", \"young\", \"which\", \"mouth\"\n",
        "]\n",
        "\n",
        "# 단어 리스트를 공백을 기준으로 토큰화합니다.\n",
        "all_tokens = word_tokenize(word_string)\n",
        "\n",
        "# 모든 토큰을 소문자로 변환하고 불용어를 제거하여 단어의 빈도를 계산합니다.\n",
        "word_freq = Counter(token.lower() for token in all_tokens if token.lower() not in stopwords)\n",
        "\n",
        "# 워드 클라우드 생성\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
        "\n",
        "# 워드 클라우드를 matplotlib로 출력합니다.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "POON0yW2KAAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud\n",
        "!pip install transformers\n",
        "\n",
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "VG8pop-QKNpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j2Fa1_c1KXja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv(\"/content/1. Piccini Memoro Rosso N.V..csv\" , encoding='cp949')"
      ],
      "metadata": {
        "id": "gO8phrl00sVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "eWHTACI5UzBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "n_Foei00U2uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1[~df1['Review'].isnull()]"
      ],
      "metadata": {
        "id": "iPuC5QxjU5uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Artemis1111/lingua-py.git"
      ],
      "metadata": {
        "id": "9_lu1jmpU72X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lingua import Language, LanguageDetectorBuilder\n",
        "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH, Language.RUSSIAN, Language.CHINESE, Language.JAPANESE, Language.KOREAN, Language.PORTUGUESE, Language.ITALIAN]\n",
        "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
        "detector.detect_language_of(\"languages are awesome\")"
      ],
      "metadata": {
        "id": "UhYKe9KqU9ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_eng_remove(df, review_str):\n",
        "  review_revised = []\n",
        "  for review in df[review_str]:\n",
        "    if detector.detect_language_of(review) != Language.ENGLISH:\n",
        "      review = None\n",
        "    review_revised.append(review)\n",
        "  return review_revised"
      ],
      "metadata": {
        "id": "WZAE7iutVIl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans_review = []\n",
        "for review in df1['Review']:\n",
        "  ans_review.append(str(review))\n",
        "df1[\"Review\"] = ans_review"
      ],
      "metadata": {
        "id": "PrMTJlu4VLTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Review'] = non_eng_remove(df1, 'Review')"
      ],
      "metadata": {
        "id": "qQwvCEuoVN0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# 단어 분류 기준\n",
        "flavor_dict = {\"Astringency\": \"tannins\", \"dryness\": \"tannins\", \"Austere\": \"tannins\", \"Bitterness\": \"tannins\", \"Coarse\": \"tannins\",\n",
        "               \"Hard\": \"tannins\", \"Harsh\": \"tannins\", \"Mouthfeel\": \"tannins\", \"Tannins\": \"tannins\", \"Oak\": \"tannins\", \"Oaky\": \"tannins\",\n",
        "               \"structured\" : \"tannins\", \"Grippy\" : \"tannins\", \"Dense\" : \"tannins\",\"oak\" : \"tannins\",\n",
        "               \"easy\": \"smooth\", \"Mouthfeel\": \"smooth\", \"vanilla\": \"smooth\", \"balanced\": \"smooth\",\n",
        "               \"flat\": \"smooth\", \"closed\": \"smooth\", \"nectar-like\": \"smooth\", \"soft\" : \"smooth\", \"Smooth\" : \"smooth\"\n",
        "}\n",
        "\n",
        "def classify_flavor(text):\n",
        "    #소문자로 바꾸고 쪼개기\n",
        "    words = text.lower().split()\n",
        "\n",
        "    #문장 속 문장부호 지우기\n",
        "    for i in range(len(words)):\n",
        "      words[i] = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', str(words[i]))\n",
        "\n",
        "    flavor_count = {\"tannins\": 0, \"smooth\": 0}\n",
        "\n",
        "    for word in words:\n",
        "        if word in flavor_dict:\n",
        "            flavor = flavor_dict[word]\n",
        "            flavor_count[flavor] += 1\n",
        "\n",
        "    if flavor_count[\"tannins\"] > flavor_count[\"smooth\"]:\n",
        "        return \"tannins\"\n",
        "    elif flavor_count[\"smooth\"] > flavor_count[\"tannins\"]:\n",
        "        return \"smooth\"\n",
        "    else:\n",
        "        return \"Unknown\""
      ],
      "metadata": {
        "id": "2l6LiVJNVPoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "\n",
        "# 가상의 리뷰 데이터셋 생성 (실제 데이터셋을 사용해야 함)\n",
        "reviews = [\n",
        "    \"이 영화 정말 재미있네요!\",\n",
        "    \"이 영화는 너무 지루해요.\",\n",
        "    \"재미있는 영화입니다.\",\n",
        "    \"별로에요.\",\n",
        "    \"괜찮은 영화였어요.\",\n",
        "    \"내 인생 최악의 영화입니다.\"\n",
        "]\n",
        "\n",
        "# 라벨링된 가상의 라벨 데이터 (실제 데이터셋에는 해당하는 라벨이 있어야 합니다)\n",
        "labels = ['긍정', '부정', '긍정', '부정', '긍정', '부정']\n",
        "\n",
        "# 데이터프레임 생성\n",
        "data = pd.DataFrame({'리뷰': reviews, '라벨': labels})\n",
        "\n",
        "# 데이터 확인\n",
        "print(data)"
      ],
      "metadata": {
        "id": "pMmnmCHahIVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 데이터들\n",
        "reviews = df1[\"Review\"]\n",
        "\n",
        "# 분류된 문장들을 저장할 리스트\n",
        "tannins_reviews = []\n",
        "smooth_reviews = []\n",
        "unknown_reviews = []\n",
        "\n",
        "for review in reviews:\n",
        "    # 리뷰 데이터에서 문장 부분만 추출\n",
        "    flavor_class = classify_flavor(review)\n",
        "\n",
        "    # Dry와 Sweet으로 분류된 문장들을 각각의 리스트에 추가\n",
        "    if flavor_class == \"tannins\":\n",
        "        dry_reviews.append(review)\n",
        "    elif flavor_class == \"smooth\":\n",
        "        sweet_reviews.append(review)\n",
        "    elif flavor_class == \"Unknown\":\n",
        "        unknown_reviews.append(review)\n",
        "\n",
        "# 분류 결과 출력\n",
        "print(\"tannins Reviews:\")\n",
        "for review in dry_reviews:\n",
        "    print(\"\\n\" + \"-\"*100 + '\\n', review)\n",
        "\n",
        "print(\"\\n\"*10)\n",
        "\n",
        "print(\"\\nsmooth Reviews:\")\n",
        "for review in sweet_reviews:\n",
        "    print(\"\\n\" + \"-\"*100 + '\\n', review)\n",
        "\n",
        "print(\"\\n\"*10)\n",
        "\n",
        "print(\"\\nUnknown Reviews:\")\n",
        "for review in unknown_reviews:\n",
        "    print(\"\\n\" + \"-\"*100 + '\\n', review)"
      ],
      "metadata": {
        "id": "FFyFB2hCbAi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####여기까지1!!!!!!###########"
      ],
      "metadata": {
        "id": "ULxg50btfncN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()\n",
        "df1 = df1[~df1['Review'].isnull()]"
      ],
      "metadata": {
        "id": "5ufTtnl8bHeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "import re"
      ],
      "metadata": {
        "id": "nQN6gz8qcTbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "tokenized_text = []\n",
        "\n",
        "# 3. 문장 데이터를 단어화하기\n",
        "for val in df1[\"Review\"]:\n",
        "\n",
        "  # 문장을 string으로 만들기\n",
        "  val = str(val)\n",
        "\n",
        "  # 문장을 소문자로 바꾸기\n",
        "  val = val.lower()\n",
        "\n",
        "  #문장 속 문장부호 지우기\n",
        "  val = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', val)\n",
        "\n",
        "  # 문장을 쪼개기\n",
        "  tokens = val.split()\n",
        "\n",
        "  tokenized_text.append(tokens)\n",
        "  comment_words += \" \".join(tokens) + \" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bTSLnJMdE8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필터링할 추가적인 stopwords들 정의\n",
        "\n",
        "stopwords_Rose = ['wine', 'good', 'nice', 'nose', 'really', 'first', 'great', 'little',\n",
        "                  'high', 'easy', 'top', 'color', 'long', 'tasty', 'excellent', 'very', 'notes',\n",
        "                  'taste', 'colour', 'still', 'one', 'well', 'perfect', 'drink', 'aftertaste',\n",
        "                  'value'\n",
        "]\n",
        "stopwords_name = ['provence'\n",
        "]"
      ],
      "metadata": {
        "id": "k8yFSdzTdINR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text[0]"
      ],
      "metadata": {
        "id": "cvpk3_Z0dQAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_stopwords(tokenized_text, stopwords_2, stopword_3):\n",
        "  tokenized_filtered = []\n",
        "\n",
        "  for i in tokenized_text:\n",
        "    for word in i:\n",
        "      if word not in stopwords and word not in stopwords_2 and word not in stopword_3:\n",
        "        tokenized_filtered.append(word)\n",
        "\n",
        "  return tokenized_filtered"
      ],
      "metadata": {
        "id": "XsJgBoXmdR3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_text)"
      ],
      "metadata": {
        "id": "5eOV8ehxdUNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_filtered = filter_stopwords(tokenized_text, stopwords_Rose, stopwords_name)"
      ],
      "metadata": {
        "id": "Bew9230adWLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_filtered[0:10]"
      ],
      "metadata": {
        "id": "FF-5BtiUdYHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_filtered)"
      ],
      "metadata": {
        "id": "wEQG-i9sdZpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "\n",
        "def word_count(tokenized_data):\n",
        "  word_counter = {}\n",
        "\n",
        "  for i in tokenized_data:\n",
        "    if i in word_counter.keys():\n",
        "      word_counter[i] += 1\n",
        "    else:\n",
        "      word_counter[i] = 1\n",
        "\n",
        "  # 많이 나온 순서대로 정렬\n",
        "\n",
        "  sorted_dict = dict( sorted(word_counter.items(),\n",
        "                           key=operator.itemgetter(1), reverse=True))\n",
        "\n",
        "  return sorted_dict"
      ],
      "metadata": {
        "id": "-GVbQhKhdbQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dict = word_count(tokenized_filtered)"
      ],
      "metadata": {
        "id": "UPIgJlOZddc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 상위 20개의 단어 보기\n",
        "def top_20(tokenized_dict):\n",
        "  top_20_words = list(tokenized_dict.items())[:100]\n",
        "  return top_20_words\n",
        "\n",
        "top_20(tokenized_dict)"
      ],
      "metadata": {
        "id": "WEEq2YwUdfMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wc = WordCloud(background_color=\"white\", min_font_size=10)\n",
        "cloud = wc.generate_from_frequencies(tokenized_dict)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.axis('off')\n",
        "plt.imshow(cloud)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RDqM6zKZdhGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "flavor_dict = {\n",
        "    \"Astringency\": \"tannins\", \"dryness\": \"tannins\", \"Austere\": \"tannins\", \"Bitterness\": \"tannins\", \"Coarse\": \"tannins\",\n",
        "    \"Hard\": \"tannins\", \"Harsh\": \"tannins\", \"Mouthfeel\": \"tannins\", \"Tannins\": \"tannins\", \"Oak\": \"tannins\", \"Oaky\": \"tannins\",\n",
        "    \"structured\" : \"tannins\", \"Grippy\" : \"tannins\", \"Dense\" : \"tannins\",\"oak\" : \"tannins\",\n",
        "    \"easy\": \"smooth\", \"Mouthfeel\": \"smooth\", \"vanilla\": \"smooth\", \"balanced\": \"smooth\",\n",
        "    \"flat\": \"smooth\", \"closed\": \"smooth\", \"nectar-like\": \"smooth\", \"soft\" : \"smooth\", \"Smooth\" : \"smooth\"\n",
        "}"
      ],
      "metadata": {
        "id": "i86vIAm1dkOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "flavors_dict = defaultdict(int)\n",
        "\n",
        "flavors_list = []\n",
        "\n",
        "for k, v in tokenized_dict.items():\n",
        "  for key, value in flavor_dict.items():\n",
        "    if k == key:\n",
        "      flavors_list.append((value, v))\n",
        "\n",
        "for k, v in flavors_list:\n",
        "  if k in flavors_dict:\n",
        "    flavors_dict[k] += v\n",
        "  else:\n",
        "    flavors_dict[k] = v\n",
        "\n",
        "flavors_dict = OrderedDict(sorted(flavors_dict.items(),\n",
        "                            key=lambda item: item[1],\n",
        "                            reverse=True))\n",
        "\n",
        "flavors_dict"
      ],
      "metadata": {
        "id": "aPoPKtB5d667"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotly로 시각화\n",
        "\n",
        "# Pie Chart\n",
        "import plotly.express as px\n",
        "\n",
        "flavors = pd.Series(flavors_dict)\n",
        "\n",
        "fig = px.pie(flavors, values=flavors, names=flavors.index, title=\"가장 두드러지게 나타난 감정\", hover_data=[flavors], labels=flavors.index)\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3kMyCVGLd9aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/2. Elk Cove Estate Pinot Noir.csv\", encoding=\"cp949\")"
      ],
      "metadata": {
        "id": "OUDUEcrOeAWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.isnull().sum()"
      ],
      "metadata": {
        "id": "5cXw8-Yjeg4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2[~df2['Review'].isnull()]"
      ],
      "metadata": {
        "id": "Gmh8kXdrersy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Artemis1111/lingua-py.git"
      ],
      "metadata": {
        "id": "igrO3n2dexRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lingua import Language, LanguageDetectorBuilder\n",
        "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH, Language.RUSSIAN, Language.CHINESE, Language.JAPANESE, Language.KOREAN, Language.PORTUGUESE, Language.ITALIAN]\n",
        "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
        "detector.detect_language_of(\"languages are awesome\")"
      ],
      "metadata": {
        "id": "TF2NbWzoezqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_eng_remove(df, review_str):\n",
        "  review_revised = []\n",
        "  for review in df[review_str]:\n",
        "    if detector.detect_language_of(review) != Language.ENGLISH:\n",
        "      review = None\n",
        "    review_revised.append(review)\n",
        "  return review_revised"
      ],
      "metadata": {
        "id": "SIfh1cdPe5zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans_review = []\n",
        "for review in df2['Review']:\n",
        "  ans_review.append(str(review))\n",
        "df2[\"Review\"] = ans_review"
      ],
      "metadata": {
        "id": "hhNlVqqMe708"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tannins_reviews = []\n",
        "smooth_reviews = []\n",
        "unknown_reviews = []"
      ],
      "metadata": {
        "id": "bWUgus_Pe9mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in dfs:\n",
        "  reviews = df[\"Review\"]\n",
        "\n",
        "  for review in reviews:\n",
        "    # 리뷰 데이터에서 문장 부분만 추출\n",
        "    flavor_class = classify_flavor(review)\n",
        "\n",
        "    # Dry와 Sweet으로 분류된 문장들을 각각의 리스트에 추가\n",
        "    if flavor_class == \"Dry\":\n",
        "      dry_reviews.append(review)\n",
        "    elif flavor_class == \"Sweet\":\n",
        "      sweet_reviews.append(review)\n",
        "    elif flavor_class == \"Unknown\":\n",
        "      unknown_reviews.append(review)"
      ],
      "metadata": {
        "id": "PrTIvBdahaN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/1. Piccini Memoro Rosso N.V..csv' , encoding='cp949')\n",
        "df2 = pd.read_csv('/content/2. Elk Cove Estate Pinot Noir.csv' , encoding='cp949')\n",
        "df3 = pd.read_csv('/content/3. Bodega Norton Malbec D.O.C..csv' , encoding='cp949')\n",
        "df4 = pd.read_csv('/content/4. Antinori Villa Antinori Chianti Classico Riserva.csv' , encoding='cp949')\n",
        "df5 = pd.read_csv('/content/5. Mascota Vineyards Unánime Gran Vino Tinto.csv' , encoding='cp949')"
      ],
      "metadata": {
        "id": "RYhzaifVlDJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()\n",
        "df2.isnull().sum()\n",
        "df3.isnull().sum()\n",
        "df4.isnull().sum()\n",
        "df5.isnull().sum()\n",
        "df6.isnull().sum()\n",
        "df7.isnull().sum()\n",
        "df8.isnull().sum()\n",
        "df9.isnull().sum()\n",
        "df10.isnull().sum()\n",
        "df12.isnull().sum()\n",
        "df13.isnull().sum()\n",
        "df14.isnull().sum()\n",
        "df15.isnull().sum()\n",
        "df16.isnull().sum()"
      ],
      "metadata": {
        "id": "Z_MbM9AfyhHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = [df1, df2, df3, df4, df5]\n",
        "dfs_num = len(dfs)"
      ],
      "metadata": {
        "id": "Bt3A2B2ol8WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(dfs_num):\n",
        "  ans_review = []\n",
        "  for review in dfs[i]['Review']:\n",
        "    ans_review.append(str(review))\n",
        "  dfs[i][\"Review\"] = ans_review"
      ],
      "metadata": {
        "id": "aelhmNkWmgDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(dfs_num):\n",
        "  dfs[i]['Review'] = non_eng_remove(dfs[i], 'Review')"
      ],
      "metadata": {
        "id": "hfoTTguymkxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1[~df1['Review'].isnull()]\n",
        "df2 = df2[~df2['Review'].isnull()]\n",
        "df3 = df3[~df3['Review'].isnull()]\n",
        "df4 = df4[~df4['Review'].isnull()]\n",
        "df5 = df5[~df5['Review'].isnull()]\n",
        "df6 = df6[~df6['Review'].isnull()]\n",
        "df7 = df7[~df7['Review'].isnull()]\n",
        "df8 = df8[~df8['Review'].isnull()]\n",
        "df9 = df9[~df9['Review'].isnull()]\n",
        "df10 = df10[~df10['Review'].isnull()]\n",
        "df12 = df12[~df12['Review'].isnull()]\n",
        "df13 = df13[~df13['Review'].isnull()]\n",
        "df14 = df14[~df14['Review'].isnull()]\n",
        "df15 = df15[~df15['Review'].isnull()]\n",
        "df16 = df16[~df16['Review'].isnull()]"
      ],
      "metadata": {
        "id": "FBfSVO8kBxNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# 단어 분류 기준\n",
        "flavor_dict = {\n",
        "    \"acidity\": \"acidic\", \"tart\": \"acidic\", \"crisp\": \"acidic\", \"zesty\": \"acidic\", \"brisk\": \"acidic\",\n",
        "    \"tangy\": \"acidic\", \"mouthwatering\": \"acidic\", \"bracing\": \"acidic\", \"crystalline\": \"acidic\",\n",
        "    \"mouth-puckering\": \"acidic\", \"lively\": \"acidic\", \"razor-sharp\": \"acidic\", \"piquant\": \"acidic\",\n",
        "    \"racy\": \"acidic\", \"vibrant\": \"acidic\",\n",
        "    \"astringency\": \"tannins\", \"dryness\": \"tannins\", \"austere\": \"tannins\", \"bitterness\": \"tannins\",\n",
        "    \"coarse\": \"tannins\", \"hard\": \"tannins\", \"harsh\": \"tannins\", \"mouthfeel\": \"tannins\", \"tannins\": \"tannins\",\n",
        "    \"oak\": \"tannins\", \"oaky\": \"tannins\", \"structured\": \"tannins\", \"grippy\": \"tannins\", \"dense\": \"tannins\",\n",
        "    \"oak\": \"tannins\",\n",
        "}\n",
        "\n",
        "def classify_flavor(text):\n",
        "    # 소문자로 바꾸고 쪼개기\n",
        "    words = text.split()\n",
        "\n",
        "    # 문장 속 문장부호 지우기\n",
        "    for i in range(len(words)):\n",
        "        words[i] = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]', '', str(words[i]))\n",
        "\n",
        "    flavor_count = {\"acidic\": 0, \"tannins\": 0}\n",
        "\n",
        "    for word in words:\n",
        "        if word in flavor_dict:\n",
        "            flavor = flavor_dict[word]\n",
        "            flavor_count[flavor] += 1\n",
        "\n",
        "    if flavor_count[\"acidic\"] > flavor_count[\"tannins\"]:\n",
        "        return \"acidic\"\n",
        "    elif flavor_count[\"tannins\"] > flavor_count[\"acidic\"]:\n",
        "        return \"tannins\"\n",
        "    else:\n",
        "        return \"Unknown\""
      ],
      "metadata": {
        "id": "-ej0wqwly-0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acidic_reviews = []\n",
        "tannins_reviews = []\n",
        "unknown_reviews = []\n",
        "\n",
        "# 리뷰 데이터들\n",
        "for df in dfs:\n",
        "    # 결측치 제거\n",
        "    df = df.dropna(subset=[\"Review\"])\n",
        "    reviews = df[\"Review\"]\n",
        "\n",
        "    for review in reviews:\n",
        "        # 리뷰 데이터에서 문장 부분만 추출\n",
        "        flavor_class = classify_flavor(review)\n",
        "\n",
        "        # Dry와 Sweet으로 분류된 문장들을 각각의 리스트에 추가\n",
        "        if flavor_class == \"acidic\":\n",
        "            acidic_reviews.append(review)\n",
        "        elif flavor_class == \"tannins\":\n",
        "            tannins_reviews.append(review)\n",
        "        elif flavor_class == \"Unknown\":\n",
        "            unknown_reviews.append(review)\n",
        "\n",
        "import csv\n",
        "\n",
        "def save_reviews_to_csv(filename, reviews_list):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        for review in reviews_list:\n",
        "            writer.writerow([review])\n",
        "\n",
        "\n",
        "# Save review lists to CSV files\n",
        "save_reviews_to_csv('acidic_reviews.csv', acidic_reviews)\n",
        "save_reviews_to_csv('tannins_reviews.csv', tannins_reviews)\n",
        "save_reviews_to_csv('unknown_reviews.csv', unknown_reviews)"
      ],
      "metadata": {
        "id": "cNFJLh4g0RJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##BERT 알고리즘 사용"
      ],
      "metadata": {
        "id": "ts6ktS0diZ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ],
      "metadata": {
        "id": "Ymu1hTY3DXAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "WFbmB9LYgzkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/combined_sample.csv\")"
      ],
      "metadata": {
        "id": "RZMVRXaFocsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset):\n",
        "  \"\"\" Custom Dataset class. \"\"\"\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len"
      ],
      "metadata": {
        "id": "VFKhrAWAg8HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __len__(self):\n",
        "    return len(self.reviews)"
      ],
      "metadata": {
        "id": "NvXNfRmbhWAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, idx):\n",
        "    \"\"\" Method to support indexing and return dataset[idx] \"\"\"\n",
        "    review = str(self.reviews[idx])\n",
        "    target = self.targets[idx]\n",
        "    encoding = self.tokenizer.encode_plus(review,\n",
        "                                          add_special_tokens=True,\n",
        "                                          max_length=self.max_len,\n",
        "                                          return_attention_mask=True,\n",
        "                                          return_tensors='pt',\n",
        "                                          return_token_type_ids=False,\n",
        "                                          pad_to_max_length=True,\n",
        "                                          truncation=True)\n",
        "    return {\n",
        "      'review_text' : review,\n",
        "      'input_ids' : encoding['input_ids'].flatten(),\n",
        "      'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "      'targets' : torch.tensor(target, dtype=torch.long)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "LXLX-T8RhZ42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = ReviewDataset(\n",
        "    reviews=df['Review'].to_numpy(),\n",
        "    targets=df['Label'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  # shuffle true is recommended so that batched between epochs donot look alike\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=True,\n",
        "    pin_memory=True  # For faster data transfer from host to GPU in CUDA-enabled GPUs\n",
        "  )\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  \"\"\" Function to calculate accuracy of our predictions vs labels\n",
        "  \"\"\"\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "shev3tArhcCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"BERT training for sentiment classification for 2 classes\", add_help=True)\n",
        "    parser.add_argument(\"--model_name\", type=str, default=\"bert-base-multilingual-cased\", help=\"pre-trained model name or path\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=42 , help=\"random seed value\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, required=True, help=\"batch size for training\")\n",
        "    parser.add_argument(\"--max_len\", type=int, default=100, help=\"Maximum length of sequence\")\n",
        "    parser.add_argument(\"--epoch\", type=int, default=1 , help=\"No. of training epochs\")\n",
        "    parser.add_argument(\"--model_dir\", type=str, required=True, help=\"path to directory to save model\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=2e-5, help=\"learning rate\")\n",
        "    parser.add_argument(\"--dataset_dir\", type=str, required=True, help=\"path to directory to load datasets\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    RANDOM_SEED = args.seed\n",
        "    random.seed(RANDOM_SEED)\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)"
      ],
      "metadata": {
        "id": "YKhTEpbYhe3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "        self.reviews = reviews\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        review = str(self.reviews[item])\n",
        "        target = self.targets[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'review': review,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'target': torch.tensor(target, dtype=torch.long)\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "SriLLWASqtEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터를 훈련용, 검증용, 테스트용으로 나눔\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initializing model based tokenizer\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME, do_lower_case=False)\n",
        "\n",
        "# 각 데이터셋에 대한 데이터 로더 생성\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_loader = create_data_loader(train_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "id": "Eh6xSMYzhx6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# BERT 모델 정의\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, pretrained_model_name, num_labels):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# 모델 초기화\n",
        "NUM_LABELS = 2  # 클래스 개수에 따라 적절히 변경\n",
        "model = BERTClassifier(PRETRAINED_MODEL_NAME, NUM_LABELS)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# 모델 학습\n",
        "EPOCHS = 4  # 적절한 epoch 수로 변경\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        #targets = torch.argmax(targets, dim=1)\n",
        "        loss = criterion(outputs, targets)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_data_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "Ow-6IlzupcHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "model.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        _, predicted_labels = torch.max(outputs, dim=1)\n",
        "\n",
        "        total_predictions += targets.size(0)\n",
        "        correct_predictions += (predicted_labels == targets).sum().item()\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "##로딩되다가 안됨 : 실패"
      ],
      "metadata": {
        "id": "ibrw9IsnNS5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "Zlsc5Tx-sPKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud\n",
        "!pip install transformers\n",
        "!pip install transformers[torch]\n",
        "%pip install numpy==1.23.4\n",
        "\n",
        "\n",
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Bert 사용에 필요한 모듈 불러오기\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, Adafactor, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 여기 오류는 엘리스떄 처럼 넘파이 버전 오류임.\n",
        "# 넘파이를 1.23.4 버전으로 바꾸니 성공.\n",
        "\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "4uaYgkxZsR_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 파일 불러오기\n",
        "combine_df = pd.read_csv('/content/combined_dry_sweet.csv')"
      ],
      "metadata": {
        "id": "TSmPH3pHHTVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "#엇 근데 GPU 사용 못하는거 같은데\n",
        "\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "metadata": {
        "id": "fCFW391Pg5Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label 데이터 str에서 int로 바꿔주기\n",
        "int_labels = []\n",
        "\n",
        "for i in range(len(df['Label'])):\n",
        "    int_labels.append(int(df['Label'][i]))\n",
        "\n",
        "df['Label'] = int_labels"
      ],
      "metadata": {
        "id": "48zqKZxioIET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "tmp_review = []\n",
        "tmp_label = []\n",
        "\n",
        "lst = [i for i in range(len(df))]\n",
        "print(lst) # 기존의 0~2999까지의 인덱스\n",
        "\n",
        "random.seed(SEED)\n",
        "random.shuffle(lst)\n",
        "print(lst) # 순서가 섞인 0~2999까지의 인덱스\n",
        "\n",
        "# 순서 인덱스에 맞춰서 Review와 Label을 섞어준다.\n",
        "for i in lst:\n",
        "  tmp_review.append(df[\"Review\"][i])\n",
        "  tmp_label.append(df[\"Label\"][i])\n",
        "\n",
        "df[\"Review\"] = tmp_review\n",
        "df[\"Label\"] = tmp_label"
      ],
      "metadata": {
        "id": "LHnSwwrroLA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2FyD7rEoos8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}